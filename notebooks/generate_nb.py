import json
import os

notebook_content = {
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVAMITVA Water Body Segmentation\n",
    "## High-Accuracy Semantic Segmentation Pipeline\n",
    "\n",
    "**Objective**: Segment water bodies (polygons, lines, points) from drone orthophotos with \u226595% accuracy.\n",
    "\n",
    "**Approach**:\n",
    "1. **Data Preprocessing**: Rasterize diverse shapefiles (polygons, streams, wells) into binary masks. Buffer thin features (lines/points) to ensure learnability.\n",
    "2. **Tiling**: Slice high-res orthophotos into 512x512 chips.\n",
    "3. **Model**: U-Net with ResNet-34 encoder (Pre-trained on ImageNet).\n",
    "4. **Training**: Dice Loss + Adam Optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.windows import Window\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check Device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "ORTHO_DIR = \"../PB_training_dataSet_shp_file\"\n",
    "SHP_DIR = \"../PB_training_dataSet_shp_file/shp-file\"\n",
    "OUTPUT_DIR = \"../data/processed/water\"\n",
    "\n",
    "# Hyperparameters\n",
    "TILE_SIZE = 512\n",
    "STRIDE = 512       # Set to 256 for 50% overlap (Data Augmentation via Overlap)\n",
    "BATCH_SIZE = 8     # Adjust based on VRAM\n",
    "EPOCHS = 30\n",
    "LR = 1e-4\n",
    "\n",
    "# Create Output Dirs\n",
    "os.makedirs(f\"{OUTPUT_DIR}/images\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/masks\", exist_ok=True)\n",
    "print(f\"Output Directory: {os.path.abspath(OUTPUT_DIR)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing: Rasterization & Tiling\n",
    "This function reads large orthophotos, matches the CRS of shapefiles, buffers small features (lines/points), rasterizes them into masks, and chips them into training tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_chips(ortho_dir, shp_dir, output_dir, tile_size=512, stride=512):\n",
    "    print(\"Loading shapefiles...\")\n",
    "    try:\n",
    "        # Load all three types\n",
    "        poly_gdf = gpd.read_file(os.path.join(shp_dir, \"Water_Body.shp\"))\n",
    "        line_gdf = gpd.read_file(os.path.join(shp_dir, \"Water_Body_Line.shp\"))\n",
    "        point_gdf = gpd.read_file(os.path.join(shp_dir, \"Waterbody_Point.shp\"))\n",
    "        print(\"Shapefiles loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading shapefiles: {e}\")\n",
    "        return\n",
    "\n",
    "    ortho_files = glob.glob(os.path.join(ortho_dir, \"*.tif\"))\n",
    "    print(f\"Found {len(ortho_files)} orthophotos.\\n\")\n",
    "\n",
    "    total_chips = 0\n",
    "\n",
    "    for ortho_path in ortho_files:\n",
    "        filename = os.path.basename(ortho_path).replace('.tif', '')\n",
    "        print(f\"processing: {filename}...\")\n",
    "        \n",
    "        with rasterio.open(ortho_path) as src:\n",
    "            crs = src.crs\n",
    "            res = src.res[0] # Pixel size in map units\n",
    "            \n",
    "            # --- 1. Reproject & Buffer Shapefiles --- \n",
    "            poly_proj = poly_gdf.to_crs(crs)\n",
    "            line_proj = line_gdf.to_crs(crs)\n",
    "            point_proj = point_gdf.to_crs(crs)\n",
    "            \n",
    "            water_shps = []\n",
    "            \n",
    "            # Polygons (Use as is)\n",
    "            water_shps.extend(poly_proj.geometry.tolist())\n",
    "            \n",
    "            # Lines (Buffer to create width)\n",
    "            # Goal: Make streams at least ~2-3 meters wide or detectable\n",
    "            if not line_proj.empty:\n",
    "                # If units are meters, buffer 1.5m -> 3m width\n",
    "                buffered_lines = line_proj.geometry.buffer(2.0) \n",
    "                water_shps.extend(buffered_lines.tolist())\n",
    "                \n",
    "            # Points (Buffer to create small pools/wells)\n",
    "            if not point_proj.empty:\n",
    "                buffered_points = point_proj.geometry.buffer(3.0) \n",
    "                water_shps.extend(buffered_points.tolist())\n",
    "            \n",
    "            if not water_shps:\n",
    "                print(\"  -> No water features found for this area.\")\n",
    "                continue\n",
    "            \n",
    "            # Combine into single GeoDataFrame for indexing\n",
    "            all_gdf = gpd.GeoDataFrame(geometry=water_shps, crs=crs)\n",
    "            sindex = all_gdf.sindex\n",
    "            \n",
    "            # --- 2. Sliding Window Tiling --- \n",
    "            h, w = src.height, src.width\n",
    "            \n",
    "            idx = 0\n",
    "            for y in range(0, h, stride):\n",
    "                for x in range(0, w, stride):\n",
    "                    window = Window(x, y, tile_size, tile_size)\n",
    "                    win_bounds = rasterio.windows.bounds(window, transform=src.transform)\n",
    "                    win_box = box(*win_bounds)\n",
    "                    \n",
    "                    # Performance: Check if any water shape intersects this window\n",
    "                    possible_matches_index = list(sindex.intersection(win_box.bounds))\n",
    "                    possible_matches = all_gdf.iloc[possible_matches_index]\n",
    "                    \n",
    "                    # Refine intersection\n",
    "                    precise_matches = possible_matches[possible_matches.intersects(win_box)]\n",
    "                    \n",
    "                    # Filter Empty Tiles (Keep some negatives for robustness)\n",
    "                    if precise_matches.empty:\n",
    "                        if np.random.rand() > 0.10: # Keep 10% of background chips\n",
    "                            continue\n",
    "                    \n",
    "                    # Read Image Chip\n",
    "                    img = src.read(window=window) # (C, H, W)\n",
    "                    \n",
    "                    # Pad edge tiles\n",
    "                    c, h_win, w_win = img.shape\n",
    "                    if h_win < tile_size or w_win < tile_size:\n",
    "                        pad_h = tile_size - h_win\n",
    "                        pad_w = tile_size - w_win\n",
    "                        img = np.pad(img, ((0,0),(0,pad_h),(0,pad_w)), mode='constant')\n",
    "                    else:\n",
    "                        pad_h, pad_w = 0, 0\n",
    "                    \n",
    "                    # Rasterize Mask\n",
    "                    if not precise_matches.empty:\n",
    "                        win_transform = src.window_transform(window)\n",
    "                        mask = rasterize(\n",
    "                            shapes=precise_matches.geometry,\n",
    "                            out_shape=(h_win, w_win),\n",
    "                            transform=win_transform,\n",
    "                            fill=0,\n",
    "                            default_value=1,\n",
    "                            dtype='uint8'\n",
    "                        )\n",
    "                    else:\n",
    "                        mask = np.zeros((h_win, w_win), dtype='uint8')\n",
    "                        \n",
    "                    # Pad Mask if needed\n",
    "                    if pad_h > 0 or pad_w > 0:\n",
    "                         mask = np.pad(mask, ((0,pad_h),(0,pad_w)), mode='constant')\n",
    "                    \n",
    "                    # Save files\n",
    "                    # Img: Transpose to HWC for CV2 (BGR)\n",
    "                    img_hwc = np.moveaxis(img, 0, -1)\n",
    "                    img_bgr = cv2.cvtColor(img_hwc, cv2.COLOR_RGB2BGR)\n",
    "                    \n",
    "                    img_name = f\"{filename}_{x}_{y}.png\"\n",
    "                    cv2.imwrite(f\"{output_dir}/images/{img_name}\", img_bgr)\n",
    "                    cv2.imwrite(f\"{output_dir}/masks/{img_name}\", mask*255)\n",
    "                    \n",
    "                    idx += 1\n",
    "                    total_chips += 1\n",
    "    \n",
    "    print(f\"\\nProcessing Complete. Created {total_chips} patches.\")\n",
    "\n",
    "# Run Data Generation (Uncomment if data not yet generated)\n",
    "create_dataset_chips(ORTHO_DIR, SHP_DIR, OUTPUT_DIR, TILE_SIZE, STRIDE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        self.img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.png\")))\n",
    "        self.mask_paths = sorted(glob.glob(os.path.join(mask_dir, \"*.png\")))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load Image\n",
    "        img = cv2.imread(self.img_paths[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load Mask\n",
    "        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        # Binarize (0 or 255 -> 0 or 1)\n",
    "        mask = (mask > 127).astype(np.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            \n",
    "        # Preprocessing for Model\n",
    "        # Shape: (H, W, C) -> (C, H, W)\n",
    "        img = img.transpose(2,0,1).astype(np.float32) / 255.0\n",
    "        mask = np.expand_dims(mask, 0) # Add channel dim -> (1, H, W)\n",
    "        \n",
    "        return torch.from_numpy(img), torch.from_numpy(mask)\n",
    "\n",
    "# Augmentations\n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(scale_limit=0.1, rotate_limit=15, shift_limit=0.1, p=0.5, border_mode=0),\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, p=0.3)\n",
    "    ]\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "# Setup Dataset\n",
    "full_dataset = WaterDataset(f\"{OUTPUT_DIR}/images\", f\"{OUTPUT_DIR}/masks\", get_training_augmentation())\n",
    "print(f\"Total Training Samples: {len(full_dataset)}\")\n",
    "\n",
    "if len(full_dataset) > 0:\n",
    "    train_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "else:\n",
    "    print(\"Warning: Dataset is empty. Run 'create_dataset_chips' above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture (U-Net + ResNet34)\n",
    "We use a U-Net architecture which provides excellent localization for segmentation. The encoder is initialized with ResNet34 weights pretrained on ImageNet to accelerate convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=1,                      \n",
    ")\n",
    "\n",
    "# Loss: DiceLoss is good for segmentation consistency + BCE for pixel-wise accuracy\n",
    "loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "model.to(DEVICE)\n",
    "print(\"Model Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    loop = tqdm(loader, desc=\"Training\", leave=False)\n",
    "    for imgs, masks in loop:\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss = loss_fn(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Start Training\n",
    "if len(full_dataset) > 0:\n",
    "    print(f\"Starting training for {EPOCHS} epochs...\")\n",
    "    history = []\n",
    "    \n",
    "    for e in range(EPOCHS):\n",
    "        avg_loss = train_epoch(model, train_loader, optimizer, loss_fn)\n",
    "        history.append(avg_loss)\n",
    "        print(f\"Epoch {e+1}/{EPOCHS} | Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Save Best/Checkpoint\n",
    "        if (e+1) % 5 == 0:\n",
    "            torch.save(model.state_dict(), f\"../models/water_unet_resnet34_ep{e+1}.pth\")\n",
    "            \n",
    "    # Save Final Model\n",
    "    torch.save(model.state_dict(), \"../models/water_unet_resnet34_final.pth\")\n",
    "    print(\"Training Complete.\")\n",
    "    \n",
    "    # Plot Loss\n",
    "    plt.plot(history)\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Dice Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization & Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_prediction(index=0):\n",
    "    model.eval()\n",
    "    img_path = full_dataset.img_paths[index]\n",
    "    mask_path = full_dataset.mask_paths[index]\n",
    "    \n",
    "    # Original\n",
    "    img_orig = cv2.imread(img_path)\n",
    "    img_orig = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "    mask_orig = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Predict\n",
    "    input_tensor, _ = full_dataset[index]\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)\n",
    "        probs = logits.sigmoid().cpu().numpy()[0,0]\n",
    "        \n",
    "    pred_mask = (probs > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(img_orig)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(mask_orig, cmap='Blues')\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(pred_mask, cmap='Blues')\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "if len(full_dataset) > 0:\n",
    "    view_prediction(index=np.random.randint(0, len(full_dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

with open("notebooks/waterbodies.ipynb", "w") as f:
    json.dump(notebook_content, f, indent=1)
